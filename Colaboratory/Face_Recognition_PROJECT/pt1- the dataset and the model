זיהוי פנים- בת אל ארנון

https://www.kaggle.com/code/georgearnall/yale-face-recognition

from google.colab import drive
drive.mount('/content/drive')

!pip install mtcnn

# Imports
from matplotlib import pyplot as plt
import numpy as np
import pandas as pd
import cv2
from PIL import Image

# Confirm mtcnn was installed correctly
import mtcnn
from mtcnn.mtcnn import MTCNN
from matplotlib.patches import Rectangle

from os import listdir
from tqdm import tqdm
import pandas as pd
from sklearn.model_selection import train_test_split
import seaborn as sns
DIRECTORY = "/content/drive/MyDrive/yalefaces/"

#Data visualization
filename = "/content/drive/MyDrive/yalefaces/subject01.gif"
pixels = plt.imread(filename)

rgb_pixels = np.stack((pixels, pixels, pixels), axis=2)
print(rgb_pixels.shape)
plt.imshow(pixels)
plt.show()
# Create the detector, using default weights
detector = MTCNN()
# detect faces in the image
results = detector.detect_faces(rgb_pixels)
# draw an image with detected objects
def draw_image_with_boxes(data, result_list):
    # plot the image
    plt.imshow(data)
    # get the context for drawing boxes
    ax = plt.gca()
    # plot each box
    for result in result_list:
        # get coordinates
        x, y, width, height = result['box']
        # create the shape
        rect = Rectangle((x, y), width, height, fill=False, color='red')
        # draw the box
        ax.add_patch(rect)
    # show the plot
    plt.show()
# הפעולה מקבלת תמונה(DATA) ואת הרשימה של המיקום של הריבוע שלה שמתמקד בפנים ומציירת את התמונה עם ריבוע אדום על הפנים. 
# display faces on the original image
draw_image_with_boxes(rgb_pixels, results)
Data preparation
The next step is to extract and normalise the face pixels so that they can reliably be used for classifying.
# extract a single face from a given photograph
def extract_face_from_file(filename, required_size=(160, 160)):
# load image from file
    image = Image.open(filename)

    return extract_face(image, required_size)
# הפונקציה מקבלת שם של קובץ וגודל רצוי ופותחת אותו ושולחת אותו לפונקציה הבאה לחילוץ הפנים.
def extract_face(image, required_size=(160, 160)):
    # convert to RGB, if needed
    image = image.convert('RGB')
    # convert to array
    pixels = np.asarray(image)
    # detect faces in the image
    results = detector.detect_faces(pixels)
    # extract the bounding box from the first face
    x1, y1, width, height = results[0]['box']
    # bug fix
    x1, y1 = abs(x1), abs(y1)
    x2, y2 = x1 + width, y1 + height
    # extract the face
    face = pixels[y1:y2, x1:x2]
    # resize pixels to the model size
    image = Image.fromarray(face)
    image = image.resize(required_size)
    face_array = np.asarray(image)
    gray_face = cv2.cvtColor(face_array, cv2.COLOR_BGR2GRAY)

    return gray_face
#הפונקציה מקבלת תמונה וגודל רצוי ומחזירה תמונה בגרייסקייל רק של הפנים

# Create the detector, using default weights
detector = MTCNN()
# load the photo and extract the face
face_pixels = extract_face_from_file("/content/drive/MyDrive/yalefaces/subject01.gif")
plt.imshow(face_pixels)
#Building the dataset
We need to extract the faces for all of the images so that we can create our dataset for training/testing.
def list_files(directory, contains):
    return list(f for f in listdir(directory) if contains in f)
# מקבלת תיקייה ואיזשהי מילה ומחזירה רשימה של כל הקבצים שיש בהם את המילה הזו. 
i = 1
faces = list()
for filename in tqdm(list_files(DIRECTORY, "subject")[0:16]):
    # path
    path = DIRECTORY + filename
    # get face
    face = extract_face_from_file(path)
    # plot
    plt.subplot(4, 4, i)
    plt.axis('off')
    plt.imshow(face)
    faces.append(face)
    i += 1
plt.show()
#Setup the test train data
# list filenames
filenames = pd.DataFrame(list_files(DIRECTORY, "subject"))
# generate split
df = filenames[0].str.split(".", expand=True)
df["filename"] = filenames

# # tidy columns
df = df.rename(columns = {0:"subject", 1:"category"})
df['subject'] = df.subject.str.replace('subject' , '')
df.apply(pd.to_numeric, errors='coerce').dropna()
df['subject'] = pd.to_numeric(df["subject"])
#Test Train Split
PER_CLASS = 8 # 11 images (3 test & 8 train)
NO_CLASSES = 15
DS_SIZE = df["subject"].count()
TEST_SIZE = 1 - (PER_CLASS * NO_CLASSES / DS_SIZE)

# # list files for each group
# # df.groupby(['subject'])['filename'].apply(list)
y = df['subject']
X = df.drop('subject',axis=1)
# # subject
X_train_info, X_test_info, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=45, stratify=y)
y_train = y_train.tolist()
y_test = y_test.tolist()

#Extract the faces
detector = MTCNN()

def load_dataset(dataset):
    faces = list()
    for filename in tqdm(dataset["filename"]):
        path = DIRECTORY + filename
        # get face
        face = extract_face_from_file(path)
        faces.append(face)
    return np.asarray(faces)
#מקבל מידע של הקבצים, פותח אותם ומחלץ את הפנים ומכניס לרשימה. מחזיר אותה במערך
X_test = load_dataset(X_test_info)
X_train = load_dataset(X_train_info)
# מערכים של נתונים
print(X_test.shape)
print(X_train.shape)

from tensorflow.keras.preprocessing.image import ImageDataGenerator
def data_generator():
return ImageDataGenerator(
        rescale=1./255,
    )
#Training a Convolutional Neural Network
# Options

TRAINING_DATA_DIRECTORY = "data/train"
TESTING_DATA_DIRECTORY = "data/test"
NUM_CLASSES = 15
EPOCHS = 30
BATCH_SIZE = 20
NUMBER_OF_TRAINING_IMAGES = 120
NUMBER_OF_TESTING_IMAGES = 45
IMAGE_HEIGHT = 160
IMAGE_WIDTH = 160
from tensorflow.keras.preprocessing.image import ImageDataGenerator
def data_generator():
    return ImageDataGenerator(
        rescale=1./255,
    )
# הפונקציה מחזירה ImageDataGenerator. 
Save the dataset to disk to load into keras
import os 
def save_keras_dataset(setname, dataset, labels, per_class):
    # combine labels and images to generate files
    data = sorted(list(zip(labels, dataset)), key=lambda x: x[0])
    # Save images
    j = 0
    for label, gray_img in tqdm(data):
        j = (j% per_class) + 1
        # Create directory
        directory = f"data/{setname}/class_{label}/"
        if not os.path.exists(directory):
                os.makedirs(directory)
        cv2.imwrite(f"{directory}class_{label}_{j}.png",gray_img)
#הפונקציה מקבלת שם, דטהסט, שמות לתיקיות וכמות תמונות בקלאס ושומרת אותן בתיקייה.
# clear directory if it already exists
import shutil
shutil.rmtree(r'data', ignore_errors=True)
# Save datasets
save_keras_dataset("test", X_test, y_test, 3)
save_keras_dataset("train", X_train, y_train, 8)

# Setup Data Generators
training_generator = data_generator().flow_from_directory(
    TRAINING_DATA_DIRECTORY,
    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    color_mode='grayscale'
)
#מחזיק IMAGE DATA ITERATOR על כל התמונות בתיקייה TRAIN
testing_generator = data_generator().flow_from_directory(
    TESTING_DATA_DIRECTORY,
    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),
    class_mode='categorical',
    color_mode='grayscale'
)
#מחזיק IMAGE DATA ITERATOR על כל התמונות בתיקייה TEST
validation_generator = data_generator().flow_from_directory(
    TESTING_DATA_DIRECTORY,
    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=False # IMPORTANT: to ensure classes line up with batches
)
#מחזיק IMAGE DATA ITERATOR על כל התמונות בתיקייה TEST
#Model preparation and training
import keras
class MCDropout(keras.layers.Dropout):
    def call(self, inputs):
        return super().call(inputs, training=True)
from tensorflow.keras import models
from tensorflow.keras.layers import Activation, ZeroPadding2D, MaxPooling2D, Conv2D, Flatten, Dense, Dropout
from tensorflow.keras import regularizers, constraints

# Define a sequential keras model
model = models.Sequential()

# 1st Convolution layer
model.add(Conv2D(32, kernel_size=(3, 3), activation='linear', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 1), padding='same'))
model.add(MaxPooling2D((2, 2)))

# 2nd Convolution layer
model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(l2=0.01)))
model.add(MaxPooling2D(pool_size=(2, 2)))

# 3rd Convolution layer
model.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(l2=0.01)))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Flatten the Convolution
model.add(Flatten())

# Define a dense layer with l2 regularizer to reduce overfitting
model.add(Dense(512, activation='relu', kernel_initializer="glorot_uniform", kernel_regularizer=regularizers.l2(l2=0.01)))

# Define a drop layer to reduce overfitting
model.add(MCDropout(rate=0.5))

# Final output layer
model.add(Dense(NUM_CLASSES, activation='softmax', kernel_initializer="glorot_uniform"))
model.summary()

from keras.utils import plot_model
plot_model(model, show_shapes=True, show_layer_names=True)
from tensorflow.keras import optimizers, losses
from tensorflow.keras.callbacks import EarlyStopping
early_stopping = EarlyStopping()

model.compile(
    loss=losses.CategoricalCrossentropy(from_logits=True),
    optimizer=optimizers.Adam(learning_rate=0.0003),
    metrics=["accuracy"]
)

history = model.fit(
    training_generator,
    steps_per_epoch=(NUMBER_OF_TRAINING_IMAGES//BATCH_SIZE ),
    epochs=EPOCHS,
    validation_data=testing_generator,
    shuffle=True,
    validation_steps=(NUMBER_OF_TESTING_IMAGES//BATCH_SIZE),
#     callbacks=[early_stopping]
)
#Performance evaluation

plot_folder = "plot"
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.1, 1])
plt.legend(loc='lower right')
plot_folder = "plot"
plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.xlabel('Epoch')
plt.ylabel('Val Loss')

plt.legend(loc='lower right')
import seaborn as sns
predictions = model.predict(testing_generator)
predicted_labels = np.argmax(predictions, axis=1)

# confusion matrix
true_labels = testing_generator.classes
cm = confusion_matrix(true_labels, predicted_labels)

plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=testing_generator.class_indices, yticklabels=testing_generator.class_indices)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support

Y_pred = model.predict(validation_generator)
y_pred = np.argmax(Y_pred, axis=1)
print(classification_report(validation_generator.classes, y_pred))
print(validation_generator.classes)
print(y_pred)
print('Confusion Matrix')
print(confusion_matrix(validation_generator.classes, y_pred))

#Save the model

MODEL_NAME = "keras_face_recognition.h5"
model_path = "./model"
if not os.path.exists(model_path):
    os.mkdir(model_path)
model.save(os.path.join(model_path, MODEL_NAME))
class_names = training_generator.class_indices
class_names_file_reverse = MODEL_NAME[:-3] + "_class_names_reverse.npy"
class_names_file = MODEL_NAME[:-3] + "_class_names.npy"
np.save(os.path.join(model_path, class_names_file_reverse), class_names)
class_names_reversed = np.load(os.path.join(model_path, class_names_file_reverse), allow_pickle=True).item(
class_names = dict([(value, key) for key, value in class_names_reversed.items()])
np.save(os.path.join(model_path, class_names_file), class_names)

model.save('/content/drive/MyDrive/model2')
#Sample Testing
def get_sample_test_image():
    """Chooses a random image from the testing set"""

    # Choose image sample
    expected_class = random.randint(1, NUM_CLASSES)
    random_sample = random.randint(1, 3)

    # Build image path
    image_path = f"data/test/class_{expected_class}/class_{expected_class}_{random_sample}.png"

    # Read the file

    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    # Return the results
    return img, expected_class
# מחזירה את תמונה רנדומלית ואת הY שלה
def preprocess_image(img):
    """Ensures the image is the correct shape and normalises the pixels"""

    image = Image.fromarray(img)
    image = image.resize((160,160))
    face_array = np.asarray(image)
    # expands the dimensions
    face_array = face_array.reshape(160,160,1)

    face_array = face_array.astype('float32')
    scaled_image = np.expand_dims(face_array, axis=0)

    return scaled_image
# מעצבת את התמונה לצורת הנכונה ומנרמלת את הפיקסלים
  def prediction(image, debug=True):
    # show the image
    plt.imshow(image)
    plt.show()

    # Process the sample
    input_sample = preprocess_image(img)
   # Prediction
    results = model.predict(input_sample)
    result = np.argmax(results, axis=1)
    index = result[0]

    # Calculate Confidence
    confidence = results[0][index] * 100
    classes = np.load(os.path.join("model", class_names_file), allow_pickle=True).item()
    # Get class name
    if type(classes) is dict:
        for k, v in classes.items():
            if k == index:
                class_name = v
    if debug:
        print(results)
        print("Detected class is {} with {:.2f}% confidence".format(class_name, round(confidence, 2)))

    # Return results
    return class_name
# פונקציה שמקבלת תמונה וחוזה את האיש. מחזירה את שמו- לפי המספר הגבוה ביותר במערך אחרי שחוזים זה המקום של האדם במערך
# Choose an image
img, expected_class = get_sample_test_image()

print(f"Expected class: {expected_class}")

prediction(img), f"expected:{expected_class}"
#Monte Carlo Dropout
def monte_carlo_prediction(image, debug=True):
    # show the image
    plt.imshow(image)
    plt.show()

    # Process the sample
    input_sample = preprocess_image(img)

    # Prediction
    results = np.stack([model(input_sample, training=True) for _ in range(100)])

    # Calucate Results

    results_mean = results.mean(axis=0)
    results_std = results.std(axis=0)
    index = np.argmax(results_mean,axis=1)

    # Calculate Confidence
    confidence = results_mean[0][index][0] * 100

    classes = np.load(os.path.join("model", class_names_file), allow_pickle=True).item()
    if type(classes) is dict:
        for k, v in classes.items():
            if k == index:
                class_name = v

    if (debug):
        print(f'Mean = {np.round(results_mean[:1],2)}')
        print(f'Std  = {np.round(results_std[:1],2)}')
        print(confidence)
        print("detected class is {} with {:.2f}% confidence".format(class_name, round(confidence, 2)))

    return class_name
#מקבלת תמונה וחוזה בשיטת מונטהקרלו- עם הממוצע
# Choose an image
img, expected_class = get_sample_test_image()
print(f"expected class {expected_class}")
monte_carlo_prediction(img)

def load_model(model_path):
    """
    Load a TensorFlow model from the specified path.
    Args:
    - model_path (str): Path to the saved model directory.
    Returns:
    - loaded_model: TensorFlow model loaded from the specified path.
    """
    try:
        loaded_model = tf.keras.models.load_model(model_path)
        print("Model loaded successfully!")
        return loaded_model
    except Exception as e:
        print("Error loading the model:", str(e))
        return None
